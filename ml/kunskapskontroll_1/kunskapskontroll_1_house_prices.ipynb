{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34dbb2c8-9ee6-4d36-837c-adac438d7e83",
   "metadata": {},
   "source": [
    "# Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f1456e",
   "metadata": {},
   "source": [
    "With AI-modelling and Data Science there is plenty of opportunity to improve processes or suggest improved ways of doing things. When doing so it is often very smart and efficient (time is a scarce resource) to create a POC (Proof of Concept) which basically is a small demo checking wether it is worthwile going further with something. It is also something concrete which facilitates discussions, do not underestimate the power of that. \n",
    "\n",
    "In this example, you are working in a company that sells houses and they have a \"manual\" process of setting prices by humans. You as a Data Scientist can make this process better by using Machine Learning. Your task is to create a POC that you will present to your team colleagues and use as a source of discussion of wether or not you should continue with more detailed modelling. \n",
    "\n",
    "Two quotes to facilitate your reflection on the value of creating a PoC: \n",
    "\n",
    "\"*Premature optimization is the root of all evil*\". \n",
    "\n",
    "\"*Fail fast*\".\n",
    "\n",
    "\n",
    "**More specifially, do the following:**\n",
    "1. A short EDA (Exploratory Data Analysis) of the housing data set.\n",
    "2. Drop the column `ocean_proximity`, then you only have numeric columns which will simplify your analysis. Remember, this is a POC! \n",
    "3. You have missing values in your data (not sure you do but you can assume so). Handle this with `SimpleImputer(strategy=\"median\")`. (Check the fantastic Scikit-learn documentation for details.) Notice, the `SimpleImputer` should only be used for transformation on the validation and test data, not fitting.\n",
    "4. Split your data into `X` and `y`, and then into train, validation and test sets. \n",
    "5. Create one `LinearRegression` model and one `Lasso` model. For the `Lasso` model, use `GridSearchCV` to optimize $\\alpha$ values. Choose yourself which $\\alpha$ values to evaluate.\n",
    "Use RMSE as a metric to decide which model to choose. \n",
    "\n",
    "6. Which model is best on the validation data? \n",
    "\n",
    "7. Evaluate your chosen model on the test set using the root mean squared error (RMSE) as the metric. \n",
    "What are your conclusions? Note: to be 100% sure, you should re-fit your chosen model on the combination of train+val data. \n",
    "\n",
    "8. Do a short presentation (~ 2-5 min) on your POC that you present to your colleagues (no need to prepare anything particular, just talk from the code). Think of:\n",
    "- What do you want to highlight/present?\n",
    "- What is your conclusion?\n",
    "- What could be the next step? Is the POC convincing enough or is it not worthwile continuing? Do we need to dig deeper into this before taking some decisions?\n",
    "\n",
    "------------\n",
    "Bonus question for those who have time and are ambitious: Redo everything above (copy your code) but in step 2, include the column `ocean_proximity` which is a categorical column. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96931ff",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4fcb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147ea5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below, set your own path where you have stored the data file if it is not in the /data folder. \n",
    "housing = pd.read_csv(r'data/housing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee19169",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aeeb407-92b9-4ed3-bcdc-89198b82edfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8fae163",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c59056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a66dbc2",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e18b60a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bcc2be2f",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8414e00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "128a5959",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4208ba68",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
